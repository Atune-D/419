#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®­ç»ƒ/å¾®è°ƒåµŒå…¥æ¨¡å‹ï¼ˆå½“æ£€ç´¢ä¸è¾¾æ ‡æ—¶ä½¿ç”¨ï¼‰

ä½¿ç”¨ MultipleNegativesRankingLoss è®­ç»ƒåµŒå…¥æ¨¡å‹
é€‚ç”¨äºæå‡æ£€ç´¢æ€§èƒ½

Usage:
    # åŸºç¡€è®­ç»ƒ
    python train_embedding.py \
      --train data/working/threads.train.jsonl \
      --valid data/working/threads.valid.jsonl \
      --base-model intfloat/e5-base-v2 \
      --output models/e5-finetuned
    
    # å¿«é€Ÿè®­ç»ƒï¼ˆ1 epochï¼‰
    python train_embedding.py \
      --train data/working/threads.train.jsonl \
      --base-model intfloat/e5-base-v2 \
      --epochs 1 \
      --output models/e5-finetuned-quick
"""

import argparse
import jsonlines
import random
from pathlib import Path
from dataclasses import dataclass
from typing import List, Tuple

def load_threads(path):
    """åŠ è½½ threads"""
    return list(jsonlines.open(path))

def last_customer_turn(thread):
    """è·å–æœ€åä¸€æ¡å®¢æˆ·é‚®ä»¶"""
    for turn in reversed(thread.get("turns", [])):
        if turn.get("role") == "customer":
            scsa = turn.get("scsa")
            body = turn.get("body", "")
            return scsa if isinstance(scsa, str) and scsa else body
    return None

def thread_to_text(thread):
    """å°† thread è½¬æ¢ä¸ºæ–‡æœ¬ï¼ˆç”¨äºæ­£æ ·æœ¬ï¼‰"""
    parts = []
    for turn in thread.get("turns", [])[:4]:  # å‰4ä¸ªturns
        scsa = turn.get("scsa", "")
        if isinstance(scsa, str) and scsa:
            parts.append(scsa)
        role = turn.get("role", "").upper()
        subj = turn.get("subject", "")
        body = turn.get("body", "")
        parts.append(f"[{role}] {subj}\n{body}")
    return "\n\n".join(parts)

def create_training_samples(threads, samples_per_thread=1):
    """
    åˆ›å»ºè®­ç»ƒæ ·æœ¬ (query, positive)
    
    Args:
        threads: list of thread dicts
        samples_per_thread: æ¯ä¸ªthreadç”Ÿæˆå¤šå°‘ä¸ªæ ·æœ¬
    
    Returns:
        list of (query, positive) tuples
    """
    samples = []
    
    for thread in threads:
        query = last_customer_turn(thread)
        if not query:
            continue
        
        positive = thread_to_text(thread)
        if not positive:
            continue
        
        for _ in range(samples_per_thread):
            samples.append((query, positive))
    
    return samples

def train_model(train_samples, base_model, output_dir, 
                epochs=2, batch_size=16, valid_samples=None, 
                warmup_steps=100, learning_rate=2e-5):
    """
    è®­ç»ƒåµŒå…¥æ¨¡å‹
    
    Args:
        train_samples: list of (query, positive) tuples
        base_model: åŸºç¡€æ¨¡å‹åç§°
        output_dir: è¾“å‡ºç›®å½•
        epochs: è®­ç»ƒè½®æ•°
        batch_size: batch size
        valid_samples: éªŒè¯é›†æ ·æœ¬
        warmup_steps: warmup steps
        learning_rate: å­¦ä¹ ç‡
    """
    try:
        from sentence_transformers import SentenceTransformer, InputExample, losses
        from torch.utils.data import DataLoader
    except ImportError:
        print("âŒ sentence-transformers not installed!")
        print("   Install with: pip install sentence-transformers")
        return False
    
    print(f"ğŸ“¦ Loading base model: {base_model}")
    model = SentenceTransformer(base_model)
    
    # è½¬æ¢ä¸º InputExample
    print(f"ğŸ”„ Converting {len(train_samples)} samples to InputExamples...")
    train_examples = [
        InputExample(texts=[query, positive])
        for query, positive in train_samples
    ]
    
    # åˆ›å»º DataLoader
    train_dataloader = DataLoader(
        train_examples, 
        shuffle=True, 
        batch_size=batch_size
    )
    
    # å®šä¹‰ loss
    train_loss = losses.MultipleNegativesRankingLoss(model)
    
    # éªŒè¯é›†ï¼ˆå¯é€‰ï¼‰
    evaluator = None
    if valid_samples:
        from sentence_transformers.evaluation import InformationRetrievalEvaluator
        
        print(f"ğŸ”„ Preparing validation evaluator with {len(valid_samples)} samples...")
        
        # æ„å»ºéªŒè¯ç”¨çš„æŸ¥è¯¢å’Œè¯­æ–™åº“
        queries = {}
        corpus = {}
        relevant_docs = {}
        
        for i, (query, positive) in enumerate(valid_samples[:100]):  # æœ€å¤š100ä¸ªéªŒè¯æ ·æœ¬
            query_id = f"q{i}"
            doc_id = f"d{i}"
            
            queries[query_id] = query
            corpus[doc_id] = positive
            relevant_docs[query_id] = {doc_id}
        
        evaluator = InformationRetrievalEvaluator(
            queries, corpus, relevant_docs,
            name="validation"
        )
    
    # è®­ç»ƒ
    print(f"\nğŸš€ Starting training...")
    print(f"  Base model:    {base_model}")
    print(f"  Train samples: {len(train_samples)}")
    print(f"  Epochs:        {epochs}")
    print(f"  Batch size:    {batch_size}")
    print(f"  Warmup steps:  {warmup_steps}")
    print(f"  Learning rate: {learning_rate}")
    print(f"  Output:        {output_dir}\n")
    
    model.fit(
        train_objectives=[(train_dataloader, train_loss)],
        epochs=epochs,
        warmup_steps=warmup_steps,
        evaluator=evaluator,
        evaluation_steps=500 if evaluator else 0,
        output_path=output_dir,
        save_best_model=True if evaluator else False,
        show_progress_bar=True,
    )
    
    print(f"\nâœ… Training complete!")
    print(f"   Model saved to: {output_dir}")
    
    return True

def main():
    parser = argparse.ArgumentParser(description="Train/fine-tune embedding model")
    parser.add_argument("--train", required=True, help="Training JSONL file")
    parser.add_argument("--valid", help="Validation JSONL file (optional)")
    parser.add_argument("--base-model", default="intfloat/e5-base-v2",
                       help="Base model to fine-tune")
    parser.add_argument("--output", required=True, help="Output directory for fine-tuned model")
    parser.add_argument("--epochs", type=int, default=2, help="Number of epochs")
    parser.add_argument("--batch-size", type=int, default=16, help="Batch size")
    parser.add_argument("--samples-per-thread", type=int, default=1,
                       help="Training samples per thread")
    parser.add_argument("--warmup-steps", type=int, default=100, help="Warmup steps")
    parser.add_argument("--learning-rate", type=float, default=2e-5, help="Learning rate")
    parser.add_argument("--seed", type=int, default=42, help="Random seed")
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    random.seed(args.seed)
    
    # åŠ è½½æ•°æ®
    print(f"ğŸ“‚ Loading training data from: {args.train}")
    train_threads = load_threads(args.train)
    print(f"âœ… Loaded {len(train_threads)} training threads")
    
    valid_threads = None
    if args.valid:
        print(f"ğŸ“‚ Loading validation data from: {args.valid}")
        valid_threads = load_threads(args.valid)
        print(f"âœ… Loaded {len(valid_threads)} validation threads")
    
    # åˆ›å»ºè®­ç»ƒæ ·æœ¬
    print(f"\nğŸ”¨ Creating training samples...")
    train_samples = create_training_samples(
        train_threads, 
        samples_per_thread=args.samples_per_thread
    )
    print(f"âœ… Created {len(train_samples)} training samples")
    
    valid_samples = None
    if valid_threads:
        print(f"ğŸ”¨ Creating validation samples...")
        valid_samples = create_training_samples(valid_threads, samples_per_thread=1)
        print(f"âœ… Created {len(valid_samples)} validation samples")
    
    # æ£€æŸ¥æ ·æœ¬è´¨é‡
    if len(train_samples) < 100:
        print(f"\nâš ï¸  Warning: Only {len(train_samples)} training samples!")
        print(f"   Consider generating more data or increasing --samples-per-thread")
    
    # è®­ç»ƒ
    output_dir = Path(args.output)
    success = train_model(
        train_samples=train_samples,
        base_model=args.base_model,
        output_dir=str(output_dir),
        epochs=args.epochs,
        batch_size=args.batch_size,
        valid_samples=valid_samples,
        warmup_steps=args.warmup_steps,
        learning_rate=args.learning_rate,
    )
    
    if success:
        print(f"\nğŸ’¡ Next steps:")
        print(f"  # Evaluate the fine-tuned model")
        print(f"  python eval_matrix.py \\")
        print(f"    --test data/working/threads.test.jsonl \\")
        print(f"    --models {output_dir} \\")
        print(f"    --granularities thread turn")
        print(f"")
        print(f"  # Compare with base model")
        print(f"  python eval_matrix.py \\")
        print(f"    --test data/working/threads.test.jsonl \\")
        print(f"    --models {args.base_model} {output_dir} \\")
        print(f"    --granularities turn")

if __name__ == "__main__":
    main()


