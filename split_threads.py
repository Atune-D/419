#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŒ‰ä¸»é¢˜åˆ†å±‚æŠ½æ ·åˆ†å‰² threads ä¸º train/valid/test (80/10/10)
ç¡®ä¿å„é›†åˆçš„ä¸»é¢˜åˆ†å¸ƒä¸€è‡´ï¼Œé¿å…æ•°æ®æ³„éœ²

Usage:
    python split_threads.py --input data/raw/threads.jsonl --output data/working
    python split_threads.py --input output/all_threads.jsonl
"""

import argparse
import jsonlines
import random
import collections
from pathlib import Path

def split_threads_stratified(threads, train_ratio=0.8, valid_ratio=0.1, seed=7):
    """
    æŒ‰ä¸»é¢˜åˆ†å±‚æŠ½æ ·åˆ†å‰²
    
    Args:
        threads: list of thread dicts
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        valid_ratio: éªŒè¯é›†æ¯”ä¾‹
        seed: éšæœºç§å­
    
    Returns:
        (train, valid, test) tuples of thread lists
    """
    random.seed(seed)
    
    # æŒ‰ topic åˆ†æ¡¶
    buckets = collections.defaultdict(list)
    no_topic = []
    
    for th in threads:
        topic = th.get("topic", None)
        if topic:
            buckets[topic].append(th)
        else:
            no_topic.append(th)
    
    if no_topic:
        print(f"âš ï¸  Warning: {len(no_topic)} threads without topic, assigning to 'other'")
        buckets["other"] = no_topic
    
    # åˆ†å±‚æŠ½æ ·
    train, valid, test = [], [], []
    
    print("\nğŸ“Š Stratified sampling by topic:")
    print("-" * 70)
    print(f"{'Topic':<20} {'Total':>8} {'Train':>8} {'Valid':>8} {'Test':>8}")
    print("-" * 70)
    
    for topic, items in sorted(buckets.items(), key=lambda x: -len(x[1])):
        random.shuffle(items)
        n = len(items)
        
        # è®¡ç®—åˆ†å‰²ç‚¹
        n_train = int(train_ratio * n)
        n_valid = int(valid_ratio * n)
        
        # è‡³å°‘ä¿è¯æ¯ä¸ªé›†åˆæœ‰1ä¸ªæ ·æœ¬ï¼ˆå¦‚æœæ€»æ•°>=3ï¼‰
        if n >= 3:
            n_train = max(1, n_train)
            n_valid = max(1, n_valid)
            # è°ƒæ•´ç¡®ä¿æ€»å’Œä¸è¶…è¿‡ n
            if n_train + n_valid >= n:
                n_train = n - 2
                n_valid = 1
        
        # åˆ†å‰²
        train_items = items[:n_train]
        valid_items = items[n_train:n_train + n_valid]
        test_items = items[n_train + n_valid:]
        
        train.extend(train_items)
        valid.extend(valid_items)
        test.extend(test_items)
        
        print(f"{topic:<20} {n:>8} {len(train_items):>8} {len(valid_items):>8} {len(test_items):>8}")
    
    print("-" * 70)
    print(f"{'TOTAL':<20} {len(threads):>8} {len(train):>8} {len(valid):>8} {len(test):>8}")
    print("-" * 70)
    
    # æ‰“ä¹±æœ€ç»ˆé¡ºåº
    random.shuffle(train)
    random.shuffle(valid)
    random.shuffle(test)
    
    return train, valid, test

def save_jsonl(threads, path):
    """ä¿å­˜ threads åˆ° JSONL æ–‡ä»¶"""
    path = Path(path)
    path.parent.mkdir(parents=True, exist_ok=True)
    
    with jsonlines.open(path, "w") as writer:
        for th in threads:
            writer.write(th)
    
    print(f"âœ… Saved {len(threads)} threads â†’ {path}")

def main():
    parser = argparse.ArgumentParser(description="Split threads by stratified sampling on topics")
    parser.add_argument("--input", required=True, help="Input JSONL file with all threads")
    parser.add_argument("--output", default="data/working", help="Output directory")
    parser.add_argument("--train-ratio", type=float, default=0.8, help="Train ratio (default: 0.8)")
    parser.add_argument("--valid-ratio", type=float, default=0.1, help="Valid ratio (default: 0.1)")
    parser.add_argument("--seed", type=int, default=7, help="Random seed (default: 7)")
    args = parser.parse_args()
    
    # éªŒè¯æ¯”ä¾‹
    test_ratio = 1.0 - args.train_ratio - args.valid_ratio
    if test_ratio < 0.05:
        print("âŒ Error: test_ratio too small! Adjust train/valid ratios.")
        return
    
    print(f"ğŸ“‚ Loading threads from: {args.input}")
    
    try:
        with jsonlines.open(args.input) as reader:
            threads = list(reader)
    except Exception as e:
        print(f"âŒ Error reading file: {e}")
        return
    
    if len(threads) == 0:
        print("âŒ Error: No threads found in input file!")
        return
    
    print(f"âœ… Loaded {len(threads)} threads")
    
    # æ•°æ®è´¨é‡æ£€æŸ¥
    missing_topic = sum(1 for th in threads if not th.get("topic"))
    missing_turns = sum(1 for th in threads if not th.get("turns"))
    
    if missing_topic > 0:
        print(f"âš ï¸  Warning: {missing_topic} threads missing 'topic' field")
    if missing_turns > 0:
        print(f"âŒ Error: {missing_turns} threads missing 'turns' field!")
        return
    
    # åˆ†å±‚åˆ†å‰²
    train, valid, test = split_threads_stratified(
        threads, 
        train_ratio=args.train_ratio,
        valid_ratio=args.valid_ratio,
        seed=args.seed
    )
    
    # ä¿å­˜
    output_dir = Path(args.output)
    save_jsonl(train, output_dir / "threads.train.jsonl")
    save_jsonl(valid, output_dir / "threads.valid.jsonl")
    save_jsonl(test, output_dir / "threads.test.jsonl")
    
    # ç»Ÿè®¡æ‘˜è¦
    print("\nğŸ“ˆ Summary:")
    print(f"  Input:  {args.input}")
    print(f"  Output: {args.output}/threads.{{train,valid,test}}.jsonl")
    print(f"  Total:  {len(threads)} threads")
    print(f"  Split:  {len(train)} / {len(valid)} / {len(test)} = {args.train_ratio:.0%} / {args.valid_ratio:.0%} / {test_ratio:.0%}")
    print(f"  Seed:   {args.seed}")
    
    print("\nğŸ’¡ Next steps:")
    print(f"  # Verify data quality")
    print(f"  python quality_check.py --file {output_dir}/threads.train.jsonl")
    print(f"")
    print(f"  # Run evaluation")
    print(f"  python eval_matrix.py --test {output_dir}/threads.test.jsonl --models intfloat/e5-base-v2")

if __name__ == "__main__":
    main()


