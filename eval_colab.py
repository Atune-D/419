#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Colab ä¸“ç”¨è¯„ä¼°è„šæœ¬ - ç®€åŒ–ç‰ˆ

ç›´æ¥å¤åˆ¶åˆ° Colab è¿è¡Œï¼Œæˆ–è€…åœ¨ Colab ä¸­ï¼š
!wget https://your-url/eval_colab.py
!python eval_colab.py --test data/Testing.jsonl
"""

import argparse
import jsonlines
import re
import numpy as np
import time
from tqdm.auto import tqdm
import pandas as pd

def setup_colab():
    """æ£€æµ‹æ˜¯å¦åœ¨ Colab ç¯å¢ƒå¹¶è®¾ç½®"""
    try:
        from google.colab import files
        IN_COLAB = True
        print("âœ… Running in Google Colab")
    except ImportError:
        IN_COLAB = False
        print("â„¹ï¸  Running locally")
    return IN_COLAB

def load_threads(path):
    """åŠ è½½ threads"""
    return list(jsonlines.open(path))

def tokenize(s):
    """ç®€å•åˆ†è¯"""
    return re.findall(r"[a-z0-9]+", (s or "").lower())

def build_docs(threads, granularity="turn"):
    """æ„å»ºæ£€ç´¢æ–‡æ¡£"""
    ids, texts = [], []
    seen = set()
    
    if granularity == "thread":
        for th in threads:
            scsa = "\n".join([t.get("scsa","") for t in th.get("turns",[]) 
                             if isinstance(t.get("scsa"), str)])
            raw = "\n\n".join([f"[{t.get('role','').upper()}] {t.get('subject','')}\n{t.get('body','')}" 
                              for t in th.get("turns",[])[:4]])
            text = (scsa + "\n" + raw).strip()
            if text and text not in seen:
                ids.append(th["thread_id"])
                texts.append(text)
                seen.add(text)
    else:  # turn-level
        for th in threads:
            for i, t in enumerate(th.get("turns",[])):
                scsa = t.get("scsa","") if isinstance(t.get("scsa"), str) else ""
                text = (scsa + "\n" + f"[{t.get('role','').upper()}] {t.get('subject','')}\n{t.get('body','')}").strip()
                if text and text not in seen:
                    ids.append(f"{th['thread_id']}#t{i}")
                    texts.append(text)
                    seen.add(text)
    
    return ids, texts

def last_customer_query(th):
    """æå–æœ€åä¸€æ¡å®¢æˆ·é‚®ä»¶"""
    for t in reversed(th.get("turns",[])):
        if t.get("role") == "customer":
            scsa = t.get("scsa")
            if isinstance(scsa, str) and scsa.strip():
                return scsa
            body = t.get("body","").strip()
            if body:
                return body
    return None

def extract_thread_id(doc_id):
    """ä»æ–‡æ¡£IDæå–thread_id"""
    return doc_id.split("#")[0]

def run_experiment(test_threads, model_name, granularity, k, use_rerank=False):
    """è¿è¡Œå•æ¬¡å®éªŒ"""
    from sentence_transformers import SentenceTransformer, CrossEncoder
    import faiss
    
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ {model_name.split('/')[-1]} | {granularity}-level")
    if use_rerank:
        print(f"   + Cross-encoder reranking")
    print(f"{'='*60}")
    
    # æ„å»ºæ–‡æ¡£
    doc_ids, doc_texts = build_docs(test_threads, granularity)
    print(f"ğŸ“š {len(doc_texts)} documents")
    
    # åŠ è½½æ¨¡å‹
    print(f"ğŸ“¦ Loading embedding model...")
    emb = SentenceTransformer(model_name)
    
    # ç¼–ç 
    print(f"ğŸ”¨ Encoding documents...")
    E = emb.encode(
        doc_texts, 
        batch_size=128,  # Colab GPU å¯ä»¥ç”¨æ›´å¤§çš„ batch
        normalize_embeddings=True, 
        convert_to_numpy=True, 
        show_progress_bar=True
    )
    
    # FAISS ç´¢å¼•
    index = faiss.IndexFlatIP(E.shape[1])
    index.add(E)
    
    # Rerankerï¼ˆå¯é€‰ï¼‰
    reranker = None
    if use_rerank:
        print(f"ğŸ¯ Loading reranker...")
        reranker = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")
    
    # è¯„ä¼°
    total, hit, rr_sum = 0, 0, 0.0
    t0 = time.time()
    
    print(f"ğŸ” Evaluating...")
    for th in tqdm(test_threads, desc="Queries"):
        q = last_customer_query(th)
        if not q:
            continue
        
        # å‘é‡æ£€ç´¢
        vq = emb.encode([q], normalize_embeddings=True, convert_to_numpy=True)
        retrieve_k = 100 if use_rerank else k
        D, I = index.search(vq, min(retrieve_k, len(doc_texts)))
        
        candidates = [(doc_ids[idx], doc_texts[idx]) for idx in I[0]]
        
        # é‡æ’ï¼ˆå¯é€‰ï¼‰
        if reranker:
            pairs = [(q, text) for _, text in candidates[:100]]
            scores = reranker.predict(pairs)
            reranked = sorted(zip(candidates[:100], scores), key=lambda x: x[1], reverse=True)
            top_ids = [doc_id for (doc_id, _), _ in reranked[:k]]
        else:
            top_ids = [doc_id for doc_id, _ in candidates[:k]]
        
        # è®¡ç®—æŒ‡æ ‡
        total += 1
        retrieved = [extract_thread_id(d) for d in top_ids]
        if th["thread_id"] in retrieved:
            hit += 1
            rank = retrieved.index(th["thread_id"]) + 1
            rr_sum += 1.0 / rank
    
    elapsed = time.time() - t0
    recall = hit / total if total > 0 else 0.0
    mrr = rr_sum / total if total > 0 else 0.0
    
    # æ‰“å°ç»“æœ
    status = "âœ… PASS" if recall >= 0.80 and mrr >= 0.50 else "âŒ FAIL"
    print(f"\n{status} Results:")
    print(f"  Recall@{k}: {recall:.3f}")
    print(f"  MRR@{k}:    {mrr:.3f}")
    print(f"  Time:      {elapsed:.1f}s")
    print(f"  Queries:   {total}")
    
    return {
        "model": model_name,
        "granularity": granularity,
        "rerank": int(use_rerank),
        "k": k,
        "recall": round(recall, 3),
        "mrr": round(mrr, 3),
        "time": round(elapsed, 1),
        "queries": total,
    }

def main():
    parser = argparse.ArgumentParser(description="Colab-optimized retrieval evaluation")
    parser.add_argument("--test", required=True, help="Test JSONL file")
    parser.add_argument("--models", nargs="+", 
                       default=["sentence-transformers/all-MiniLM-L6-v2", "intfloat/e5-base-v2"],
                       help="Models to evaluate")
    parser.add_argument("--granularities", nargs="+", default=["thread", "turn"],
                       help="Document granularities")
    parser.add_argument("--k", type=int, default=10, help="K for Recall@K and MRR@K")
    parser.add_argument("--rerank", action="store_true", help="Enable reranking")
    parser.add_argument("--out", default="results.csv", help="Output CSV file")
    args = parser.parse_args()
    
    # æ£€æµ‹ Colab
    IN_COLAB = setup_colab()
    
    # åŠ è½½æ•°æ®
    print(f"\nğŸ“‚ Loading test data: {args.test}")
    test_threads = load_threads(args.test)
    print(f"âœ… Loaded {len(test_threads)} threads\n")
    
    # è¿è¡Œå®éªŒ
    results = []
    rerank_options = [False, True] if args.rerank else [False]
    total_exp = len(args.models) * len(args.granularities) * len(rerank_options)
    exp_num = 0
    
    print(f"ğŸš€ Running {total_exp} experiments...\n")
    
    for model in args.models:
        for gran in args.granularities:
            for rerank in rerank_options:
                exp_num += 1
                print(f"\n{'#'*60}")
                print(f"Experiment {exp_num}/{total_exp}")
                print(f"{'#'*60}")
                
                try:
                    result = run_experiment(test_threads, model, gran, args.k, rerank)
                    results.append(result)
                except Exception as e:
                    print(f"âŒ Error: {e}")
    
    # ç”ŸæˆæŠ¥å‘Š
    if results:
        df = pd.DataFrame(results)
        df = df.sort_values(["recall", "mrr"], ascending=False)
        
        # æ·»åŠ çŠ¶æ€åˆ—
        df["status"] = df.apply(
            lambda r: "âœ… PASS" if r["recall"] >= 0.80 and r["mrr"] >= 0.50 else "âŒ FAIL",
            axis=1
        )
        df["model_short"] = df["model"].apply(lambda x: x.split("/")[-1][:30])
        
        # æ‰“å°è¡¨æ ¼
        print(f"\n{'='*80}")
        print(f"ğŸ“Š RESULTS SUMMARY")
        print(f"{'='*80}")
        
        display_df = df[["model_short", "granularity", "rerank", "recall", "mrr", "time", "status"]]
        display_df.columns = ["Model", "Granularity", "Rerank", "Recall@10", "MRR@10", "Time(s)", "Status"]
        print(display_df.to_string(index=False))
        print(f"{'='*80}\n")
        
        # æœ€ä½³é…ç½®
        best = df.iloc[0]
        print(f"ğŸ† BEST CONFIGURATION:")
        print(f"  Model:       {best['model']}")
        print(f"  Granularity: {best['granularity']}")
        print(f"  Rerank:      {'Yes' if best['rerank'] else 'No'}")
        print(f"  Recall@10:   {best['recall']:.3f}")
        print(f"  MRR@10:      {best['mrr']:.3f}")
        print(f"\nğŸ¯ Target: Recall@10 â‰¥ 0.80, MRR@10 â‰¥ 0.50\n")
        
        # ä¿å­˜ç»“æœ
        df.to_csv(args.out, index=False)
        print(f"âœ… Results saved to: {args.out}")
        
        # å¦‚æœåœ¨ Colabï¼Œè‡ªåŠ¨ä¸‹è½½
        if IN_COLAB:
            from google.colab import files
            print(f"ğŸ“¥ Downloading {args.out}...")
            files.download(args.out)
        
        print(f"\nğŸ‰ Done!")

if __name__ == "__main__":
    main()


